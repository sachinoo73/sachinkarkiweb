group_by(word) %>%
dplyr::summarise(frequency=n())
reviewsentiment %>% wordcloud2()
review_affin_lexicon <- reviewsentiment %>%
dplyr::select(word) %>%
inner_join(get_sentiments("afinn")) %>%
mutate(sentiment=ifelse(value>0,"positive","negative"),score=value)
review_affin_lexicon
ggplot(review_affin_lexicon,aes(x=reorder(word,score),y=score,colour=sentiment,fill=sentiment))+
geom_col(alpha=0.5)+
coord_flip()
review_bing_lexicon <- reviewsentiment %>%
inner_join(get_sentiments("bing")) %>%
dplyr::count(word,sentiment,frequency,sort=TRUE) %>%
acast(word~sentiment,value.var="frequency",fill=0) %>%
comparison.cloud(max.words = 150)
#Term frequencies across essays
tidy_review <- select_(alreviews,"comments")
n <- nrow(tidy_review)
tidy_review <- data_frame(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words, just to illstrate
myterms <- c("airbnb","very","stay", "singapore", "host") #can build model to add in custom stopwords?
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies across essays
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
total_words <- review_words %>%
group_by(review) %>%
summarize(total = sum(n))
#Term frequencies across essays
tidy_review <- select_(alreviews,"comments")
n <- nrow(tidy_review)
tidy_review <- data_frame(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words, just to illstrate
myterms <- c("airbnb","very","stay", "singapore", "host") #can build model to add in custom stopwords?
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies across essays
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
review_words <- left_join(review_words, total_words)
#  now tf_idf
review_words <- review_words %>%
bind_tf_idf(word, review, n) %>%
arrange(desc(tf_idf))
glimpse(review_words)
#Term frequencies
tidy_review <- select_(alreviews,"comments")
n <- nrow(tidy_review)
tidy_review <- data_frame(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words
myterms <- c("airbnb","very","stay", "singapore", "host") #can build model to add in custom stopwords?
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
review_words <- left_join(review_words, total_words)
#  now tf_idf
review_words <- review_words %>%
bind_tf_idf(word, review, n) %>%
arrange(desc(tf_idf))
glimpse(review_words)
#Term frequencies
tidy_review <- select_(alreviews,"comments")
n <- nrow(tidy_review)
tidy_review <- data_frame(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words
myterms <- c("airbnb","very","stay", "singapore", "host") #can build model to add in custom stopwords?
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
review_words <- left_join(review_words, total_words)
#  now tf_idf
review_words <- review_words %>%
bind_tf_idf(word, review, n) %>%
arrange(desc(tf_idf))
glimpse(review_words)
#Term frequencies across essays
tidy_review <- select_(reviews,"comments")
n <- nrow(tidy_review)
tidy_review <- data_frame(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words, just to illstrate
myterms <- c("airbnb","very", "boston","stay")
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies across essays
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
total_words <- review_words %>%
group_by(review) %>%
summarize(total = sum(n))
#Term frequencies across essays
tidy_review <- select_(reviews,"comments")
n <- nrow(tidy_review)
tidy_review <- data_frame(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words
myterms <- c("airbnb","very", "singapore","stay")
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
total_words <- review_words %>%
group_by(review) %>%
summarize(total = sum(n))
str(review_words)
total_words <- review_words %>%
group_by(as.numeric(review)) %>%
summarize(total = sum(n))
#Term frequencies across essays
tidy_review <- select_(reviews,"comments")
n <- nrow(tidy_review)
tidy_review <- data_frame(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words
myterms <- c("airbnb","very", "singapore","stay")
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
total_words <- review_words %>%
group_by(review) %>%
summarise(total = sum(n))
review_words <- left_join(review_words, total_words)
#  now tf_idf
review_words <- review_words %>%
bind_tf_idf(word, review, n) %>%
arrange(desc(tf_idf))
glimpse(review_words)
#Term frequencies across essays
tidy_review <- select(reviews,"comments")
n <- nrow(tidy_review)
tidy_review <- tibble(review=1:n, text=reviews$comments)
# Tokenize, remove stop words and NAs
data("stop_words")
#  Add some custom stop words
myterms <- c("airbnb","very", "singapore","stay")
mylex <- rep("custom", length(myterms))
myStopwords <- data.frame(word=myterms, lexicon=mylex)
myStopwords <- rbind(stop_words, myStopwords)
#Term frequencies
review_words <- tidy_review %>%
unnest_tokens(word, text) %>%
anti_join(myStopwords) %>%
count(review, word, sort=TRUE) %>%
ungroup()
total_words <- review_words %>%
group_by(review) %>%
summarise(total = sum(n))
review_words <- left_join(review_words, total_words)
#  now tf_idf
review_words <- review_words %>%
bind_tf_idf(word, review, n) %>%
arrange(desc(tf_idf))
glimpse(review_words)
setwd("E:/suyiinang/ourshinypet/codes")
#read file
#retain only necessary columns
reviews <- read_csv("data/raw/reviews.csv") %>%
subset(reviews,select=c(listing_id,comments))
glimpse(reviews)
#from the file, there are 52367 rows with 6 variables
#read file
#here, id is the listing id hence need to rename if to listing_id
#drop columns that are not needed
listings <- read_csv("data/raw/listings.csv") %>%
rename(listing_id=id) %>%
select(-c(listing_url, scrape_id, last_scraped, name, picture_url,host_url, host_about,host_thumbnail_url, host_picture_url, host_listings_count, host_verifications,calendar_updated,first_review,last_review,license))
glimpse(listings)
#merge files
data <- right_join(reviews,listings,by="listing_id")
glimpse(data)
packages <- c('tidyverse','ggstatsplot','plotly','readr','leaflet')
for (p in packages){
if (!require(p,character.only=T)){
install.packages(p)
}
library(p, character.only=T)
}
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/lising_en.csv")
# Inspect structure of the dataset
glimpse(listings)
reviews <- read_csv("./data/raw/reviews.csv")
glimpse(reviews)
data <- right_join(reviews,listings,by="listing_id")
glimpse(data)
View(data)
reviews <- read_csv("./data/raw/reviews.csv")
reviews <- read_csv("./data/clean/reviews.csv")
data <- right_join(reviews,listings,by="listing_id")
reviews <- read_csv("./data/clean/reviews.csv")
View(reviews)
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/lising_en.csv")
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/listing_en.csv")
reviews <- read_csv("./data/clean/reviews.csv")
data <- right_join(reviews,listings,by="listing_id")
glimpse(data)
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/listing_en.csv")
reviews <- read_csv("./data/clean/reviews.csv")
#merge the two files by listing_id
lst <- list(lisings,reviews)
combined <- reduce(lst, full_join, by = "listing_id") %>% replace(., is.na(.), 0)
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/listing_en.csv")
reviews <- read_csv("./data/clean/reviews.csv")
#merge the two files by listing_id
lst <- list(listings,reviews)
combined <- reduce(lst, full_join, by = "listing_id") %>% replace(., is.na(.), 0)
View(lst)
combined <- reduce(lst, full_join, by = "listing_id") %>% replace(., is.na(.), 0)
reviews <- read_csv("./data/clean/reviews.csv")
View(reviews)
reviews <- reviews %>%
pivot_wider(names_from = listing_id, values_from = comments)
View(reviews)
reviews <- read_csv('data/clean/reviews.csv')
con_reviews <- reviews %>%
select(listing_id, comments) %>%
group_b(listing_id) %>%
summarise(comments = str_c(na.omit(comments), collapse = ";"))
con_reviews <- reviews %>%
select(listing_id, comments) %>%
group_by(listing_id) %>%
summarise(comments = str_c(na.omit(comments), collapse = ";"))
View(con_reviews)
str(listings)
glimpse(listings)
status(listings)
packages <- c('tidyverse','ggstatsplot','plotly','readr','leaflet','haven','funModeling')
for (p in packages){
if (!require(p,character.only=T)){
install.packages(p)
}
library(p, character.only=T)
}
status(listings)
str(listings)
parse_number(listings$price)
listings <- listings %>%
select(-c(listing_url, scrape_id, last_scraped, name, picture_url,host_id, host_url,  host_location, host_about,host_thumbnail_url, host_picture_url, host_listings_count, neighbourhood, host_verifications,calendar_updated,calendar_last_scraped, first_review,last_review,license, description_lang))
final_listings <- listings %>%
parse_number(listings$price)
final_listings <- listings %>%
mutate(parse_number(listings$price))
View(final_listings)
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price))
final_listings$price
listings %>%
ggplot(aes(x = host_response_rate)) +
geom_histogram()
listings %>%
ggplot(aes(x = host_response_rate)) +
geom_histogram(stat=count)
listings %>%
ggplot(aes(x = host_response_rate)) +
geom_bar()
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(listings$host_response_rate))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(na.omit(listings$host_response_rate)))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("","NA")))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)
View(final_listings)
View(final_listings)
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "N/A"), locale = default_locale(), trim_ws = TRUE)
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "N/A"), locale = default_locale(), trim_ws = TRUE)
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)
mutate(host_response_rate, host_response_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE) %>%
mutate(host_response_rate, host_response_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)) %>%
mutate(host_response_rate, host_response_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)) %>%
mutate(host_response_rate, host_response_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE))
glimpse(final_listings)
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, as.numeric(as.character(listings$host_response_rate)) %>%
mutate(host_response_rate, host_response_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE))
View(final_listings)
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/listing_en.csv")
listings <- listings %>%
select(-c(host_name,listing_url, scrape_id, last_scraped, name, picture_url,host_id, host_url,  host_location, host_about,host_thumbnail_url, host_picture_url, host_listings_count, neighbourhood, bathrooms, host_verifications,calendar_updated,calendar_last_scraped, first_review,last_review,license, description_lang))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, as.numeric(as.character(listings$host_response_rate))) %>%
mutate(host_response_rate, host_response_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE))
listings <- listings %>%
select(-c(host_name,listing_url, scrape_id, last_scraped, name, picture_url,host_id, host_url,  host_location, host_about,host_thumbnail_url, host_picture_url, host_listings_count, neighbourhood, bathrooms, host_verifications,calendar_updated,calendar_last_scraped, first_review,last_review,license, description_lang))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, as.numeric(as.character(listings$host_response_rate)))
glimpse(final_listings)
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>% #remove $ sign and change type to number
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)) %>%
mutate(host_acceptance_rate, host_acceptance_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE))
glimpse(final_listings)
unique(listings$property_type)
unique(listings$bathrooms_text)
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_hist()
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_hist()
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_bar()
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_bar(bin = 20)
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_bar(bin = 10)
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_bar(bin = 20)
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_bar(bin = 20)
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_bar(bin = 50)
final_listings %>%
ggplot(aes(host_response_rate)) +
geom_bar(bins = 50)
glimpse(final_listings)
listings_status <- status(listings)
arrange(listings_status, -p_na) %>%
select(variable, q_na, p_na)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
out.width = '100%', fig.height = 4, fig.align = 'center')
packages <- c('tidyverse','ggstatsplot','plotly','readr','leaflet','haven','funModeling','rgdal','sp','tmap','sf','crosstalk','RColorBrewer','datatable','shiny')
for (p in packages){
if (!require(p,character.only=T)){
install.packages(p)
}
library(p, character.only=T)
}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
out.width = '100%', fig.height = 4, fig.align = 'center')
packages <- c('tidyverse','ggstatsplot','plotly','readr','leaflet','haven','funModeling','rgdal','sp','tmap','sf','crosstalk','RColorBrewer','datatable','shiny')
for (p in packages){
if (!require(p,character.only=T)){
install.packages(p)
}
library(p, character.only=T)
}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE,
out.width = '100%', fig.height = 4, fig.align = 'center')
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/listing_en.csv")
glimpse(listings)
packages <- c('tidyverse','ggstatsplot','plotly','readr','leaflet','haven','funModeling','rgdal','sp','tmap','sf','crosstalk','RColorBrewer','data.table','shiny')
for (p in packages){
if (!require(p,character.only=T)){
install.packages(p)
}
library(p, character.only=T)
}
# Read the csv file as a tbl_df
listings <- read_csv("./data/clean/listing_en.csv")
listings_status <- status(listings)
arrange(listings_status, -p_na) %>%
select(variable, q_na, p_na)
listings <- listings %>%
select(-c(host_name,listing_url, scrape_id, last_scraped, name, picture_url,host_id, host_url,  host_location, host_about,host_thumbnail_url, host_picture_url, host_listings_count, neighbourhood, bathrooms, host_verifications,calendar_updated,calendar_last_scraped, first_review,last_review,license, description_lang))
final_listings <- listings %>%
mutate(price, price = parse_number(listings$price)) %>%
mutate(host_response_rate, host_response_rate = parse_number(host_response_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)) %>%
mutate(host_acceptance_rate, host_acceptance_rate = parse_number(host_acceptance_rate, na = c("", "NA"), locale = default_locale(), trim_ws = TRUE))
summary(final_listings)
renderText({summary(input$variables)})
pal <- colorFactor(brewer.pal(n = 4, name = "Pastel1"), domain = final_listings$room_type)
list(
filter_checkbox("room_type", "Room Type", final_listings, ~room_type, columns = 1),
),
bscols(widths=c(3,9),
list(
checkboxGroupInput('variables','Select variables for observation',choices = final_listings, selected = 'price', width = 5)
),
renderText({summary(input$variables)})
)
freq(final_listings)
dfSummary(final_listings, style = 'grid', graph.magnif = 0.75,valid.col = FALSE)
install.packages('summarytools')
library(summarytools)
dfSummary(final_listings, valid.col = FALSE, graph.magnif = 0.75, max.tbl.height = 300, method = "render")
sidebarPanel(
checkboxGroupInput('variables','Select variables for observation',choices = final_listings, selected = c('price','room_type','reivew_scores_rating','host_is_superhost'), width = 3),
),
mainPanel(
renderText({summary(input$variables)})
)
bscols(widths=c(3,9),
checkboxGroupInput('variables','Select variables for observation',choices = final_listings, selected = c('price','room_type','reivew_scores_rating','host_is_superhost'), width = 3),
),
mainPanel(
renderText({summary(input$variables)})
)
bscols(widths=c(3,9),
checkboxGroupInput('variables','Select variables for observation',choices = final_listings, selected = c('price','room_type','reivew_scores_rating','host_is_superhost'), width = 3),
),
renderText({summary(input$variables)})
)
bscols(widths=c(3,9),
checkboxGroupInput('variables','Select variables for observation',choices = final_listings, selected = c('price','room_type','reivew_scores_rating','host_is_superhost'), width = 3),
renderText({summary(input$variables)})
)
runApp('codes/ourshinypet')
setwd("E:/suyiinang/ourshinypet/codes/ourshinypet")
runApp()
setwd("E:/suyiinang/ourshinypet/codes")
runApp()
runApp()
runApp()
runApp()
runApp()
v <- input$variables
bscols(widths=c(3,9),
list(
checkboxGroupInput('variables','Select variables for observation', choices = final_listings, selected = c('price','room_type','reivew_scores_rating','host_is_superhost'), width = 3),
numericInput("Obs", "Number of observations to view", 10)
),
summary(input$variables)
)
summary(final_listings[2])
summary(final_listings[3])
summary(final_listings[1,2,3])
summary(final_listings)
summary(final_listings['price'])
lst <- c('price','reviews_per_month')
renderText({summary(final_listing[lst])})
checkboxGroupInput('variables','Select variables for observation', choices = final_listings, selected = final_listings, width = 3)
numericInput("obs", "Number of observations to view", 10)
input <- checkboxGroupInput('variables','Select variables for observation', choices = final_listings, selected = final_listings, width = 3)
input
View(input)
selectInput('x','x variable', choices = final_listings, selected = 'price') #how to change choics to checkbox
